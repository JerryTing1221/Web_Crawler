{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "page = 1\n",
    "\n",
    "Link =[]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for p in range(0,47):\n",
    "    url = 'https://www.twtainan.net/zh-tw/attractions?sortby=Tripadvisor&page={}'  #總共46頁\n",
    "    userAgent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'\n",
    "\n",
    "    headers = {\n",
    "        'user-agent':userAgent\n",
    "    }\n",
    "\n",
    "    req = requests.get(url=url.format(page), headers=headers)\n",
    "    html = etree.HTML(req.text)\n",
    "\n",
    "    linkList = html.xpath('/html/body/div[1]/main/div[2]/ul/li/div/a/@href')\n",
    "\n",
    "\n",
    "    for i in linkList:\n",
    "        link =  'https://www.twtainan.net/' + i\n",
    "        Link.append(link)\n",
    "        \n",
    "    page+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Report = []\n",
    "for l in Link:\n",
    "    url = l\n",
    "    pageReq=requests.get(url=l , headers=headers)\n",
    "    \n",
    "    phtml = etree.HTML(pageReq.text)\n",
    "\n",
    "    pageLink = l\n",
    "\n",
    "    \n",
    "    \n",
    "    Title = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/section[1]/h2/text()')\n",
    "    print(Title)  \n",
    "\n",
    "    \n",
    "    \n",
    "    Content = ''\n",
    "    C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[2]/div/text()')\n",
    "    article= Content.join(C)\n",
    "    \n",
    "    \n",
    "    remove = '\\r\\n\\xa0'\n",
    "    for word in remove:\n",
    "        article.replace(word,'')\n",
    "    \n",
    "    \n",
    "    #判斷字串是否含有中文\n",
    "    def is_contains_chinese(article):\n",
    "        for _char in article:\n",
    "            if '\\u4e00' <= _char <= '\\u9fa5':\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    if is_contains_chinese(article) ==False:\n",
    "        C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[2]/div/div/text()')\n",
    "        article= Content.join(C)\n",
    "        \n",
    "        if is_contains_chinese(article) ==False:\n",
    "            C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[2]/div/div/div/text()')\n",
    "            article= Content.join(C)\n",
    "\n",
    "            if is_contains_chinese(article) ==False:\n",
    "                C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[2]/div/p/text()')\n",
    "                article= Content.join(C)\n",
    "                \n",
    "                if is_contains_chinese(article) ==False:\n",
    "                    C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[3]/div/text()')\n",
    "                    article= Content.join(C)\n",
    "                    \n",
    "                    if is_contains_chinese(article) ==False:\n",
    "                        C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[3]/div/p/text()')\n",
    "                        article= Content.join(C)\n",
    "                        \n",
    "                        if is_contains_chinese(article) ==False:\n",
    "                            C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[3]/div/div/text()')\n",
    "                            article= Content.join(C)\n",
    "                            \n",
    "                            if is_contains_chinese(article) ==False:\n",
    "                                C = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[3]/div/div/div/text()')\n",
    "                                article= Content.join(C)\n",
    "                                \n",
    "                                \n",
    "\n",
    "                    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #標籤 Tag\n",
    "    num = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "    for a in num:\n",
    "        for b in num:\n",
    "            if phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[{}]/div/p[{}]/span[1]/text()'.format(a,b)) ==['分類']:\n",
    "                T = phtml.xpath('/html/body/div[1]/main/div[2]/section[1]/article/section[{}]/div/p[{}]/span[2]/text()'.format(a,b))\n",
    "                Tag = ''.join(T)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "    data ={\n",
    "        '景點':Title[0],\n",
    "        '標籤':Tag,\n",
    "        '景點介紹':article.lstrip(),\n",
    "        '網址':pageLink\n",
    "    }\n",
    "\n",
    "    Report.append(data)\n",
    "    #print(\"=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Report)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('台南旅遊網.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
